# Frames

When reading a text from a story, say about the earthquake in Slabovia,
we remarkably understand the content immediately. With frames, we know
what we are looking for when we read. There are slots for all "expected
values", we precisely know where to store these expected values. For
instance, when reading "the dead toll reached 25 persons", we have an
empty slot to fill already. Because we already know that an earthquake
should have a death toll number.

The "template" that we fill in when we read about an earthquake is
a *stereotype*. Reading about a subject where we lack a stereotype, we
need to create a new frame which will work as a stereotype when we read
about the same subject the next time. This will all be stored in our
long term memory. We have stereotypes for all kinds of concepts,
like "how a professor looks like", "what happens when somebody is drunk"
etc.

## Relation to Semantic Networks

A series of frames with relations to other frames like *a kind of* can
be seen as a Semantic Network (from the lectures of the first week).
Instead of frames and relations, we have nodes and edges. The book
(chapter 9 part 1) figures illustrating this equivalency.

## Curiosity, creativity, expectations and surprise

We become *surprised* when we encounter something that we don't have a
stereotype frame for, we say that that encountering didn't meet our
*expectations*.

We will become *curious* when we had a almost matching template that
didn't completely fit, for example, if an world-unaware person reads
about earthquakes and they mention that "25 people died and 100 got
injured

# Aritificial Intelligence contra Machine Learning

In machine learning, 

# Common sense




---

For feedback please patch this document by pull requesting in [my github repo][repo]

[repo]: https://github.com/Tarrasch/cs-7637-lecture-note
